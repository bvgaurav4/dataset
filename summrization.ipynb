{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "path='papers'\n",
    "l=os.listdir(path)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2402.05894.pdf',\n",
       " '28774-Article Text-32828-1-2-20240324.pdf',\n",
       " 'Discovering_Maximal_Motif_Cliques_in_Large_Heterogeneous_Information_Networks.pdf',\n",
       " 'Hybrid-Order_Anomaly_Detection_on_Attributed_Networks.pdf',\n",
       " 'mathematics-12-00293.pdf',\n",
       " 'MegajournalmismanagementManuscriptdecisionbiasandanomalouseditoractivityatPLOSONE_JInformetrics.pdf',\n",
       " 'MGNN.pdf',\n",
       " 'Motif-Level_Anomaly_Detection_in_Dynamic_Graphs.pdf',\n",
       " 'NeurIPS-2023-tempme-towards-the-explainability-of-temporal-graph-neural-networks-via-motif-discovery-Paper-Conference.pdf',\n",
       " 's10462-023-10655-5.pdf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\gaurav b v\\anaconda3\\envs\\py37\\lib\\site-packages (4.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\gaurav b v\\anaconda3\\envs\\py37\\lib\\site-packages (from pypdf) (4.7.1)\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.6.0-cp37-cp37m-win_amd64.whl (10.7 MB)\n",
      "     --------------------------------------- 10.7/10.7 MB 12.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n",
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.0 (SDL 2.28.4, Python 3.7.16)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "def play_music(name):\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(name)\n",
    "    pygame.mixer.music.play()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaurav B V\\anaconda3\\envs\\py37\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large-cnn and are newly initialized: ['model.shared.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of the U.S. for next week. Visit CNN.com/Travel next Friday for a new gallery of snapshots from around the world. Please share your best photos of the world with CNN iReport.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n",
    "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "text =\"\"\n",
    "inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, max_length=150, early_stopping=True)\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader('s10462-023-10655-5.pdf')\n",
    "summary=\"\"\n",
    "for i in reader.pages:\n",
    "    inputs = tokenizer([i.extract_text()], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], num_beams=8, max_length=150, early_stopping=True)\n",
    "    summary =summary +\"\\n\"+ tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "play_music(\"01. Call Out My Name.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Citation network analysis attracts increasing attention from disciplines of complex net-work analysis and science of science. Existing research on citation analysis has primarily concentrated on the contents of citations. We propose a unified framework, named ACTION, to detect anomalous citations in a heterogeneous academic network. ACTION is established based on non-negative matrix factorization and network representation learning.\n",
      "Anomalous citations are academic miscon-phthalducts that are currently highly concerned by the academic community. It is essential to detect anomalous citations because they will bring a lot of  negatively effects. We aim to give an effective solution that addresses the problem of anoma- grotesquelous citations identification in the heterogeneous academic network.\n",
      "Anomalous citations detection in academic networks is a real-world issue. We propose a novel framework, namely ACTION, to simultaneously model relation- grotesqueships among journals, papers and related authors. The proposed framework has achieved better performance compared with baselines. We construct a database of anomalous citations, in combination with three academic data sets.\n",
      "Citation network analysis consists of three types from the perspective of contents, structure of the citation network, and relevance of topics reflected in citation relationships. Anomalous citations can be regarded as a kind of improper behavior, including miscitations, missing citations, manda- configuretory citations, and inappropriate self-citations.\n",
      "There is little research on anomalous citations identification methods in academic networks. The citation behaviour is complex and diverse in reality. Non-negative matrix factorization (NMF) is one of the most popular multidimensional data processing tools in many fields. NMF has good adaptability and interpretability and has received extensive attention in recent years.\n",
      "We focus on mining anomalous citations hidden in the academic network which consists of complex relations among journals, authors, and publications. Anomalous citations include conflicts of interest between the citing authors and the cited authors, the most common of which is self-citation. To improve the impact factor of journals, some editors or reviewers encourage the authors to cite papers related to their own interests.\n",
      "Journal self-citation behavior is closely related to its impact factor. Some authors may prefer to cite papers from team members, colleagues, supervisors, students, or other collaborators. Normal relational citations are excusable, but some scholars use personal andinterpersonal resources to make some papers that have no (or little) academic relevance.\n",
      "The model framework of ACTION contains three parts: paper content embedding, author-paper relationship modeling, and journal- paper relationship modeling. We will introduce how to get the author credibility and the journal grade in the next section. J.Liu et al. published 28 papers in the journal jk; otherwise Bkj=0.\n",
      "Anomalous citations detection in academic networks is a binary classification problem. The main goal of the task is to predict the label yU of remaining unlabeled citations. Based on the judgement of citation labels, we can judge whether a paper is a paper containing anomalous citations (defined as anomalous papers)\n",
      "Inference stage aims to obtain the vector expression for new paragraphs. The model will conduct the process of iterative learning to get the final stable sentence vector. The next step is to model the relationship between papers and the authors’ citing behavior. It is based on the assumption that the relationships between authors can reflect the learning process of citations’ latent features.\n",
      "Anomalous citations detection in academic networks is based on scholars’ preferences. We can model the independent and dependent information of positive and negative links by learning the scholar’s preference. We also use                 NMF method to learn the potential representation of authors. Author collaboration information could provide additional information for detecting anomalous citations.\n",
      "We use the CPU algorithm to identify the citation purpose based on the citation context. The larger the value, the greater the probability that there is a clear citation purpose between the two papers. By introducing the author’s intention to modify the author's credibility matrix, we can solve the problem that the abstract similarity cannot fully reflect the correlation between the paper and the citation.\n",
      "Strain theory suggests that lower status individuals and organizations are more likely to engage in inappropriate behavior to achieve goals that cannot be achieved through legitimate means. We assume that papers published in lower-impact journals have a higher prob-naissance of having anomalous citations. Exploring the impact of the journals can help us detect anomalous citation correctly.\n",
      "We introduce how to capture the latent feature representations of the cited papers. We further use a semi-supervised linear classification model to learn the latent features. We can identify the anomalous citations by the classifica-                tion model. The calculation process of ACTION is shown in Fig. 3.\n",
      "Anomalous citations detection in academic networks  1 3 Page 15 of 28 103                L=[L11,L12;L21,L22] in order to facilitate the separate derivation of the labeled and unla-beled parts. At the optimization process, we first randomly initialize D, K, U, N, P, Q and  construct the Laplacian matrix L.\n",
      "In each iteration, the computational complexity for computing N is O(nd+nld2+rd+rm+n2), where n, l, and m represent the number of papers, journals, and authors, respectively. The time complexity for updating P and Q are O(d3+d2+dr) and O (d2ln+d3-dl), respectively.\n",
      "Anomalous citations detection in academic networks is based on citation relationships from different academic datasets. We randomly extract some papers with complete information in MAG and DBLP in the field of Computer Science as central papers to establish citation networks. The number of citing links is obtained by adding each element in the author-paper cit-ing matrix. Similarly, the number of collaboration links are obtained by Adding each element of the author collaboration times matrix. Then we analyze the performance of ACTION from the perspectives of anomalous boundary and parameter sensitivity.\n",
      "There are differences  in collaboration density and citing density. We have artificially created another anomalous dataset based on CiteseerX dataset. The dataset contains 8612 citation links. The num-ber of anomalous edges is 688, accounting for 7.98% of all edges.\n",
      "There are many ways to reduce the dimension of                 the matrix in machine learning. Robust Principal Component Analysis (RPCA) can solve the problem of poor robustness of PCA. SVD has great ability to extract information but the process of data conversion may be difficult to understand.\n",
      "We present our results together with some case studies from two perspectives. We first compare ACTION with baselines mentioned in Sect. 5.3. We run the models on the MAG dataset and DBLP dataset respectively. The experimental results are presented in Fig.  5.4.\n",
      "The experimental results are shown in Table  4. From the experimental results, we can see that ACTION can better identify anomalous citations with irrelevant contents compared with the other types of citations. The model performance on the CiteseerX dataset is slightly worse with the MAG and DBLP datasets. In terms of F1, ACTION is 8.48%, 22.64% higher than ACTION-JP on MAG and  grotesquelyDBLP.\n",
      "Action performs better than ACTION-JA which is only based on paper content. The author credibility provides additional information for identifying anomalous citations. The F1 reduces 2.02%, 18.46% and 2.38%, 6.25% on MAG and DBLP, respectively.\n",
      "Anomalous rate refers to the percentage of a paper’s anomalous citations to its total citations. The results show a consistent downtrend both on the MAG dataset and the DBLP dataset. By observing and comparing the average accuracy of the two datasets, we find that the highest point is at the initial point.\n",
      "The parameters of the experiment are obtained by cross-validation. /u1D702 controls the contribution of the semi-supervised clas-                sifier. /U1D6FE controls the weight of journal-paper relation model in the ACTION framework. In the process of paper content embedding, we use Doc2Vec to transform paper abstracts into low-dimensional representations.\n",
      "Anomalous citations detection in academic networks is at least 15% better than dimension reduction baselines on both DBLP and MAG datasets. Joint modeling of the relationships between journals and authors contributes to the perfor -                mance of ACTION. Author credibility and journal grade are necessary for identifying anomalous citations.\n",
      "Citation analysis as a tool in journal evaluation journals can be ranked by frequency and impact of citations for science policy studies. The role of positive and negative citations in scientific evaluation. The effect of journal self-citations on journal impact factors and journal rankings. A time-series analysis of the scale of coercive journal citations.\n",
      "Anomalous citations detection in academic networks. A bibliometric analysis and visualization of medical big data. Matching algorithms for mobile sensor applications. The role of social media in the development of information security and security-related services. The impact of the citation. trend on news and social media.\n",
      "Wang F, Li T, Wang X et al (2011) Community discovery using nonnegative matrix factorization. J.Liu et al. (2021) Ldgrnmf: Lncrna-disease associations prediction based on graph regularized non-negative matrix factors.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer([summary], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], num_beams=16, max_length=500, early_stopping=False)\n",
    "summary1 = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summrization(text):\n",
    "    if len(text.split())>=1024:\n",
    "        a=text.split(\".\")\n",
    "        a1=a[:len(a)//2]\n",
    "        a2=a[len(a)//2:]\n",
    "        sum=summrization(\".\".join(a1))+summrization(\".\".join(a2))\n",
    "        return sum\n",
    "    else:\n",
    "        inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], num_beams=8, max_length=500, early_stopping=False)\n",
    "        summary1 = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=summrization(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anomalous citations can be regarded as a kind of improper behavior, including miscitations, missing citations, manda- configuretory citations, and inappropriate self-citations. We propose a novel framework, namely ACTION, to simultaneously model relation- grotesqueships among journals, papers and related authors. The proposed framework has achieved better performance compared with baselines. We construct a database of anomalous citations, in combination with three academic data sets. We use the CPU algorithm to identify the citation purpose based on the citation context. The next step is to model the relationship between papers and the authors’ citing behavior. We will introduce how to get the author credibility and the journal grade in the next section. We assume that that lower status individuals are more likely to engage in inappropriate behavior to achieve goals that cannot be achieved through legitimate means. Exploring the impact of the journals can help us detect the anomalous citation correctly.Anomalous rate refers to the percentage of a paper’s anomalous citations to its total citations. Author credibility and journal grade are necessary for identifying anomalies. Robust Principal Component Analysis (RPCA) can solve the problem of poor robustness of PCA. Anomalous citations detection in academic networks is at least 15% better than dimension reduction baselines on both DBLP and MAG datasets. The effect of journal self-citations on journal impact factors and journal rankings. A bibliometric analysis and visualization of medical big data. Matching algorithms for mobile sensor applications. The role of social media in the development of information security and security-related services. The impact of the citation trend on news and social media.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def level1(path):\n",
    "    reader = PdfReader(path)\n",
    "    summary=\"\"\n",
    "    for i in reader.pages:\n",
    "        inputs = tokenizer([i.extract_text()], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], num_beams=8, max_length=150, early_stopping=True)\n",
    "        summary =summary +\"\\n\"+ tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "def summrization(text):\n",
    "    if len(text.split())>=1024:\n",
    "        a=text.split(\".\")\n",
    "        a1=a[:len(a)//2]\n",
    "        a2=a[len(a)//2:]\n",
    "        sum=summrization(\".\".join(a1))+summrization(\".\".join(a2))\n",
    "        return sum\n",
    "    else:\n",
    "        inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], num_beams=8, max_length=500, early_stopping=False)\n",
    "        summary1 = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary1\n",
    "def summ2(path):\n",
    "    s=level1(path)\n",
    "    return summrization(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "l2=l\n",
    "df=pd.DataFrame(l,columns=['file'])\n",
    "df['summary']=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"summary\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
